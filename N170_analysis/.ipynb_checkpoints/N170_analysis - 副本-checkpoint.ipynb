{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建结果存放目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    " \n",
    "    path=path.strip()# 去除首位空格\n",
    "    path=path.rstrip(\"\\\\\")# 去除尾部 \\ 符号\n",
    "  \n",
    "    isExists=os.path.exists(path)# 判断路径是否存在\n",
    "  \n",
    "    if not isExists:\n",
    "        os.makedirs(path)\n",
    "        print(path+' 创建成功')\n",
    "        return True\n",
    "    else:\n",
    "        print(path+' 目录已存在')\n",
    "        return False\n",
    "  \n",
    "# 定义要创建的目录\n",
    "mkpath=\"results\"\n",
    "# 调用函数\n",
    "mkdir(mkpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'raw_data'\n",
    "dataFile = 'n170_data.set'\n",
    "data_file = os.path.join(data_folder,dataFile)\n",
    "data = mne.io.read_raw_eeglab(data_file, eog = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_channels('EOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data manually\n",
    "fig = data.plot(duration=5, n_channels=10, scalings=dict(eeg=80e-6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Channel location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.read_custom_montage('standard-10-5-cap385.elp')\n",
    "data.set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downsampled = data.resample(sfreq=250)\n",
    "\n",
    "'''\n",
    "This will reduce the timing precision of events\n",
    "\n",
    "To avoid this reduction in precision, the suggested pipeline for processing final data to be analyzed is:\n",
    "\n",
    "low-pass the data with mne.io.Raw.filter.\n",
    "Extract epochs with mne.Epochs.\n",
    "Decimate the Epochs object using mne.Epochs.decimate or the decim argument to the mne.Epochs object.\n",
    "\n",
    "We also provide the convenience methods mne.Epochs.resample and mne.Evoked.resample to downsample or upsample data, but these are less optimal because they will introduce edge artifacts into every epoch, whereas filtering the raw data will only introduce edge artifacts only at the start and end of the recording.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bandpass = data_downsampled.filter(l_freq=1, h_freq=35)\n",
    "# data_notch = data_downsampled.notch_filter(freqs=50)\n",
    "# data_downsampled.filter(None, 50., fir_design='firwin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data manually\n",
    "# fig = data_bandpass.plot(duration=5, n_channels=64, scalings=dict(eeg=80e-6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mastoid_ref = data_bandpass.set_eeg_reference(ref_channels=['M1', 'M2'], ch_type='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data manually\n",
    "# fig = data_mastoid_ref.plot(duration=5, n_channels=30, scalings=dict(eeg=80e-6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejecting EOG & ECG with SSP\n",
    "from mne.preprocessing import (compute_proj_ecg, compute_proj_eog)\n",
    "\n",
    "# Compute SSP/PCA projections for EOG artifacts\n",
    "eog_projs, _ = compute_proj_eog(data_mastoid_ref, n_eeg=1, reject=None,\n",
    "                                no_proj=True)\n",
    "data_rejEOG = data_mastoid_ref.add_proj(eog_projs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_projs, _ = compute_proj_ecg(data_rejEOG, n_eeg=1, reject=None, ch_name=, \n",
    "                                no_proj=True)\n",
    "data_rejECG = data_rejEOG.add_proj(ecg_projs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "events, event_id = mne.events_from_annotations(data)\n",
    "events_pick = mne.pick_events(events, exclude=[1,6,7,8])\n",
    "# Mapping Event IDs to trial descriptors\n",
    "event_dict = {'face/up': 2, 'chair/up': 3, 'face/down': 4,'chair/down': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Epoched data\n",
    "epochs = mne.Epochs(data_mastoid_ref, events_pick, event_id=event_dict, \n",
    "                    tmin=-0.2, tmax=0.8, preload=True)#baseline correction was automatically applied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reject bad epochs during configuration\n",
    "# reject = dict(eeg=100e-6)\n",
    "# epochs = mne.Epochs(data_mastoid_ref, events_pick, event_id=event_dict, reject=reject, \n",
    "#                     tmin=-0.2, tmax=0.8, preload=True)#baseline correction was automatically applied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can also reject after constructing epochs\n",
    "# reject.update({'eeg': 80e-6})\n",
    "# epochs.drop_bad(reject=reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check & reject epoch manually\n",
    "# fig = epochs.plot(picks=['eeg'], scalings=dict(eeg=100e-6), n_epochs=2, n_channels=63, block=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 使用 autoreject 库\n",
    "# # Autoreject (global) can compute the rejection dictionary automatically\n",
    "from autoreject import get_rejection_threshold  # noqa\n",
    "reject = get_rejection_threshold(epochs, ch_types='eeg')\n",
    "print(reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tmp1=epochs.copy()\n",
    "epochs_tmp1.drop_bad(reject=reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 autoreject 库\n",
    "# Autoreject (local) finds per channel thresholds:\n",
    "from autoreject import AutoReject\n",
    "\n",
    "n_interpolates = np.array([1, 2, 4])\n",
    "consensus = np.linspace(0.5, 1.0, 6)\n",
    "\n",
    "ar = AutoReject(n_interpolates, consensus, thresh_method='random_search',\n",
    "                random_state=42)\n",
    "\n",
    "epochs_tmp2=epochs.copy()\n",
    "# ar.fit(epochs['auditory/left'])\n",
    "ar.fit(epochs_tmp2)\n",
    "\n",
    "#look at the rejection thresholds for each channel\n",
    "for ch_name in epochs.info['ch_names'][:5]:\n",
    "     print('%s: %s' % (ch_name, ar.threshes_[ch_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing import (ICA, corrmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ica = ICA(n_components=61, max_pca_components=61,random_state=None, method='infomax')\n",
    "ica.fit(epochs)\n",
    "\n",
    "# 或\n",
    "# ica = mne.preprocessing.ICA（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.load_data()\n",
    "ica.plot_sources(epochs, stop=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components(inst=epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting ICA components manually\n",
    "ica.exclude = [2]  # indices chosen based on various plots above\n",
    "\n",
    "# ica.apply() changes the Raw object in-place, so let's make a copy first:\n",
    "epoch_data = epochs.copy()\n",
    "ica.apply(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica.plot_properties(epochs, picks=ica.exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Reject bad epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epoch_data.plot(picks=['eeg'], scalings=dict(eeg=100e-6), n_epochs=2, n_channels=63, block=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "EvokedArray(data, info, tmin=0.0, comment='', nave=1, kind='average', verbose=None)[source]\n",
    "data: array of shape (n_channels, n_times)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保证两个条件使用等量的trial数（有问题，待调整）\n",
    "epoch_data.equalize_event_counts(['face','chair'])\n",
    "\n",
    "face_evoked = epoch_data['face'].average()#MNE-Python can select based on partial matching of /-separated epoch labels\n",
    "chair_evoked = epoch_data['chair'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 ERP 数据\n",
    "face_evoked.save('results/face_eeg-ave.fif')  # save evoked data to disk\n",
    "chair_evoked.save('results/chair_eeg-ave.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "差异波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_evoked = mne.combine_evoked([face_evoked, chair_evoked], weights=[1,-1])\n",
    "# diff_evoked.plot(picks=['P8'])\n",
    "# plt.show()\n",
    "\n",
    "# OR\n",
    "# diff_data = face_evoked.data-chair_evoked.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Butterfly plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Butterfly plot\n",
    "fig = plt.figure()\n",
    "ax2 = fig.add_subplot(121)\n",
    "ax3 = fig.add_subplot(122)\n",
    "face_evoked.plot(gfp=True, spatial_colors=True, axes=ax2) #default exclude='bads'\n",
    "chair_evoked.plot(gfp=True, spatial_colors=True, axes=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint plot\n",
    "face_evoked.plot_joint(times=0.17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalp maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalp topographies\n",
    "# single time point\n",
    "fig=face_evoked.plot_topomap(ch_type='eeg', times=0.17, average=0.01, colorbar=True)#outlines='skirt'to see the topography stretched beyond the head circle\n",
    "fig.text(0.5, 0.05, 'average from 165-175 ms', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalp topographies\n",
    "# multiple time points\n",
    "times = np.arange(0.1, 0.3, 0.02)#间隔0.02s\n",
    "face_evoked.plot_topomap(ch_type='eeg', times=times, colorbar=True,\n",
    "                         ncols=5, nrows='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animating the topomap\n",
    "times = np.arange(0.1, 0.5, 0.01)\n",
    "fig, anim = face_evoked.animate_topomap(\n",
    "    times=times, ch_type='eeg', frame_rate=2, time_unit='s', blit=False, \n",
    "    butterfly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERP traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Evoked objects\n",
    "mne.viz.plot_compare_evokeds([face_evoked, chair_evoked], picks='P8', ylim=dict(eeg=[-20,20]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topographical subplots\n",
    "mne.viz.plot_compare_evokeds([face_evoked, chair_evoked], picks='eeg', axes='topo')\n",
    "# OR\n",
    "# mne.viz.plot_evoked_topo([face_evoked, chair_evoked])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evoked arithmetic (e.g. differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and plot difference ERP\n",
    "joint_kwargs = dict(ts_args=dict(time_unit='s'),\n",
    "                    topomap_args=dict(time_unit='s'))\n",
    "mne.combine_evoked([face_evoked, chair_evoked], weights=[1, -1]).plot_joint(**joint_kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View evoked response\n",
    "# times = 1e3 * epochs.times  # time in miliseconds\n",
    "\n",
    "ch_max_name, latency, amplitude = face_evoked.get_peak(ch_type='eeg', tmin=0.15, tmax=0.2, mode='neg', return_amplitude=True)\n",
    "\n",
    "face_evoked.plot(picks=ch_max_name)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
